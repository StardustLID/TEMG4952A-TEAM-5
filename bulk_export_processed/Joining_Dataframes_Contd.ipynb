{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read back the csv files\n",
    "job_join = pd.read_csv(\"job_join.csv\")\n",
    "org_join = pd.read_csv(\"org_join.csv\")\n",
    "job_join = job_join.drop(columns=['Unnamed: 0'])\n",
    "org_join = org_join.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, it is about the linkage between people and organization, through \"job\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since memory may not be able to handle all at once, split it into multiple dataframes before joining is safer\n",
    "job_join_arr = []\n",
    "interval = int(len(job_join) / 10)\n",
    "for i in range(10):\n",
    "    job_join_part = job_join.iloc[interval*i : interval*(i+1)]\n",
    "    job_join_arr.append(job_join_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take around half hour to run this cell\n",
    "\n",
    "#Join Organization with Job\n",
    "for i in range(10):\n",
    "    org_join = org_join.set_index('uuid').join(job_join_arr[i].set_index('job_org_uuid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop away emtpy columns to simplify the final dataframe\n",
    "org_join.dropna(how = 'all', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Have a look at the joint dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take around 15 minutes to run this cell\n",
    "\n",
    "#Let's see the info of the final DataFrame\n",
    "org_join.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The final DataFrame\n",
    "org_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#Export out as CSV, the file is around 60GB\n",
    "#org_join.to_csv('org_final_joined.csv')\n",
    "\n",
    "#Use the following code to zip before exporting\n",
    "compression_opts = dict(method = 'zip', archive_name = 'org_final_joined.csv')  \n",
    "org_join.to_csv('org_final_joined.zip', compression=compression_opts) \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Problem 1: Is the following items the same as organization itself? Can we come up a way to check? If yes, we can drop all duplications to simplify our df\n",
    "\n",
    "# e.g.\n",
    "#'ipo_country',vs 'fund_rd_country', vs 'country_code'\n",
    "#'ipo_region', vs 'fund_rd_region', vs 'state_code'\n",
    "#'ipo_city', vs 'fund_rd_city', vs 'city'\n",
    "#'person_personal_rank', vs 'personal_event_rank'\n",
    "#'total_funding_usd', vs 'total_funding', vs 'funds_raised_amount_usd' \n",
    "#'category_list', vs 'category_groups_list' (what should we use eaxctly......)\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "# Problem 2: There are multiple rows for some organization eitites, due to their multiple funding rounds, or multiple people, etc.\n",
    "#            I plan to keep here first, but we may have to come up with a way to handle this situation\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "# Problem 3: The dataframe consists of a column 'Acquirer'. I chose to join using acquiriee id instead of acquirier id,\n",
    "#            due to the intuition that venture companies are more likely to be acquired than to acquire others;\n",
    "#            However, may need to find a way to handle the situation if there is really a startup acquiring others\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "# Problem 4: If a startup company has a parent company, do we also need the information of its parent company in\n",
    "#            our dataframes. My answer is yes and know, coz not sure how much could its parent company affect it;\n",
    "#            however, after all we value a startup company all by itself. If we have to incorporate its parents' data,\n",
    "#            how do we valuate its parents? We may have to build up another dataframe, or else it would be too large. \n",
    "#            Also, if its parent is an acquirer, the situation will be much more complex.\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "# Problem 5: Now, all data are raw, many NaN data and are unprocessed, we have to preprocess all the data here at once\n",
    "#            Also, we have to extract those that are within 5 years and fintech field to be our target data.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
